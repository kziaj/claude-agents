#!/bin/bash

# Claude Command: Get Column-Level Lineage for dbt Models
# Usage: get-column-lineage MODEL_NAME COLUMN_NAME [--upstream|--downstream] [--depth N]
# Description: Traces column-level lineage using Snowflake ACCESS_HISTORY and dbt manifest

set -e

# Configuration
RESULTS_DIR="$HOME/.claude/results/column-lineage"
DBT_PROJECT_DIR="$HOME/carta/ds-dbt"
MANIFEST_PATH="$DBT_PROJECT_DIR/target/manifest.json"

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
CYAN='\033[0;36m'
NC='\033[0m'

print_status() {
    echo -e "${BLUE}[INFO]${NC} $1"
}

print_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $1"
}

print_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $1"
}

print_error() {
    echo -e "${RED}[ERROR]${NC} $1"
}

show_usage() {
    echo "Usage: get-column-lineage MODEL_NAME COLUMN_NAME [OPTIONS]"
    echo ""
    echo "Traces column-level lineage through dbt models and Snowflake query history."
    echo ""
    echo "Arguments:"
    echo "  MODEL_NAME         Name of the dbt model (e.g., core_dim_organizations)"
    echo "  COLUMN_NAME        Name of the column to trace"
    echo ""
    echo "Options:"
    echo "  --upstream         Trace upstream lineage (sources of this column)"
    echo "  --downstream       Trace downstream lineage (consumers of this column)"
    echo "  --depth N          Maximum depth to traverse (default: 3)"
    echo "  --help             Show this help message"
    echo ""
    echo "Examples:"
    echo "  get-column-lineage core_dim_organizations organization_id --upstream"
    echo "  get-column-lineage core_fct_arr amount --downstream --depth 2"
    echo ""
    echo "Output: Generates report in $RESULTS_DIR"
}

# Parse arguments
if [ $# -lt 2 ]; then
    print_error "Missing required arguments"
    show_usage
    exit 1
fi

if [ "$1" = "--help" ] || [ "$1" = "-h" ]; then
    show_usage
    exit 0
fi

MODEL_NAME="$1"
COLUMN_NAME="$2"
shift 2

# Default options
DIRECTION="both"
MAX_DEPTH=3

# Parse options
while [ $# -gt 0 ]; do
    case "$1" in
        --upstream)
            DIRECTION="upstream"
            shift
            ;;
        --downstream)
            DIRECTION="downstream"
            shift
            ;;
        --depth)
            if [ -z "$2" ] || [ "$2" -lt 1 ]; then
                print_error "Invalid depth value"
                exit 1
            fi
            MAX_DEPTH="$2"
            shift 2
            ;;
        *)
            print_error "Unknown option: $1"
            show_usage
            exit 1
            ;;
    esac
done

# Create results directory
mkdir -p "$RESULTS_DIR"

print_status "Starting column lineage analysis"
print_status "Model: $MODEL_NAME"
print_status "Column: $COLUMN_NAME"
print_status "Direction: $DIRECTION"
print_status "Max Depth: $MAX_DEPTH"

# Step 1: Validate manifest exists
print_status "Step 1: Validating dbt manifest..."

if [ ! -f "$MANIFEST_PATH" ]; then
    print_error "dbt manifest not found at $MANIFEST_PATH"
    print_error "Run 'cd $DBT_PROJECT_DIR && poetry run dbt parse' to generate it"
    exit 1
fi

print_success "Found manifest at: $MANIFEST_PATH"

# Step 2: Validate model exists
print_status "Step 2: Validating model and column..."

# Check if model exists in manifest
MODEL_EXISTS=$(python3 -c "
import json
import sys

try:
    manifest = json.load(open('$MANIFEST_PATH'))
    
    # Search for model
    found = False
    for node_id, node in manifest['nodes'].items():
        if node.get('name') == '$MODEL_NAME':
            found = True
            # Check if column exists
            columns = node.get('columns', {})
            if '$COLUMN_NAME' in [c.lower() for c in columns.keys()]:
                print('FOUND')
                sys.exit(0)
            else:
                print('MODEL_FOUND_COLUMN_MISSING')
                sys.exit(0)
    
    if not found:
        print('MODEL_NOT_FOUND')
        sys.exit(0)
        
except Exception as e:
    print(f'ERROR: {e}', file=sys.stderr)
    sys.exit(1)
")

if [ "$MODEL_EXISTS" = "MODEL_NOT_FOUND" ]; then
    print_error "Model '$MODEL_NAME' not found in dbt manifest"
    exit 1
elif [ "$MODEL_EXISTS" = "MODEL_FOUND_COLUMN_MISSING" ]; then
    print_warning "Column '$COLUMN_NAME' not found in model YAML (may still exist in Snowflake)"
fi

print_success "Model and column validated"

# Step 3: Get Snowflake table info
print_status "Step 3: Getting Snowflake table information..."

# Find the table in Snowflake
SNOWFLAKE_TABLE_INFO=$(snow sql --query "
SELECT 
    table_catalog as database_name,
    table_schema as schema_name,
    table_name,
    column_name,
    data_type
FROM information_schema.columns 
WHERE UPPER(table_name) = UPPER('$MODEL_NAME')
    AND UPPER(column_name) = UPPER('$COLUMN_NAME')
    AND table_schema IN ('DBT_CORE', 'DBT_MART', 'DBT_VERIFIED_CORE', 'DBT_VERIFIED_MART', 'DBT_STAGING', 'DBT_VERIFIED_TRANSFORM')
LIMIT 1;
" --format JSON 2>/dev/null)

if [ -z "$SNOWFLAKE_TABLE_INFO" ] || [ "$SNOWFLAKE_TABLE_INFO" = "[]" ]; then
    print_error "Column '$COLUMN_NAME' not found in model '$MODEL_NAME' in Snowflake"
    print_error "Make sure the model is deployed"
    exit 1
fi

DATABASE=$(echo "$SNOWFLAKE_TABLE_INFO" | jq -r '.[0].DATABASE_NAME')
SCHEMA=$(echo "$SNOWFLAKE_TABLE_INFO" | jq -r '.[0].SCHEMA_NAME')
TABLE=$(echo "$SNOWFLAKE_TABLE_INFO" | jq -r '.[0].TABLE_NAME')
DATA_TYPE=$(echo "$SNOWFLAKE_TABLE_INFO" | jq -r '.[0].DATA_TYPE')

print_success "Found column in Snowflake: $DATABASE.$SCHEMA.$TABLE.$COLUMN_NAME ($DATA_TYPE)"

# Step 4: Query Snowflake ACCESS_HISTORY for column lineage
print_status "Step 4: Querying Snowflake ACCESS_HISTORY (last 90 days)..."

LINEAGE_QUERY="
WITH column_lineage AS (
    SELECT
        query_id,
        query_start_time,
        user_name,
        direct_objects_accessed,
        base_objects_accessed,
        objects_modified
    FROM SNOWFLAKE.ACCOUNT_USAGE.ACCESS_HISTORY
    WHERE query_start_time >= DATEADD(day, -90, CURRENT_DATE())
        AND (
            -- Look for our column in objects accessed
            ARRAY_SIZE(direct_objects_accessed) > 0
            OR ARRAY_SIZE(base_objects_accessed) > 0
            OR ARRAY_SIZE(objects_modified) > 0
        )
    LIMIT 10000
),
filtered_lineage AS (
    SELECT
        query_id,
        query_start_time,
        user_name,
        direct_objects_accessed,
        base_objects_accessed,
        objects_modified
    FROM column_lineage
    WHERE 
        -- Check if our table and column appear in the lineage
        TO_VARCHAR(direct_objects_accessed) ILIKE '%$TABLE%'
        OR TO_VARCHAR(base_objects_accessed) ILIKE '%$TABLE%'
        OR TO_VARCHAR(objects_modified) ILIKE '%$TABLE%'
)
SELECT
    query_id,
    query_start_time,
    user_name,
    direct_objects_accessed,
    base_objects_accessed,
    objects_modified
FROM filtered_lineage
ORDER BY query_start_time DESC
LIMIT 100;
"

SNOWFLAKE_LINEAGE=$(snow sql --query "$LINEAGE_QUERY" --format JSON 2>/dev/null || echo "[]")

LINEAGE_COUNT=$(echo "$SNOWFLAKE_LINEAGE" | jq length)
print_success "Found $LINEAGE_COUNT queries with lineage information"

# Step 5: Parse dbt manifest for model dependencies
print_status "Step 5: Analyzing dbt model dependencies..."

# Create Python script to analyze lineage
LINEAGE_ANALYSIS=$(python3 << 'PYTHON_SCRIPT'
import json
import sys
from collections import defaultdict, deque

manifest_path = sys.argv[1]
model_name = sys.argv[2]
direction = sys.argv[3]
max_depth = int(sys.argv[4])

try:
    with open(manifest_path) as f:
        manifest = json.load(f)
    
    nodes = manifest['nodes']
    
    # Build dependency graph
    upstream_deps = defaultdict(list)
    downstream_deps = defaultdict(list)
    node_info = {}
    
    for node_id, node in nodes.items():
        if node.get('resource_type') != 'model':
            continue
            
        node_name = node.get('name')
        node_info[node_name] = {
            'id': node_id,
            'schema': node.get('schema'),
            'database': node.get('database'),
            'columns': list(node.get('columns', {}).keys())
        }
        
        # Build edges
        for dep_id in node.get('depends_on', {}).get('nodes', []):
            if dep_id in nodes:
                dep_name = nodes[dep_id].get('name')
                upstream_deps[node_name].append(dep_name)
                downstream_deps[dep_name].append(node_name)
    
    # BFS to find lineage
    def trace_lineage(start_model, deps_dict, max_depth):
        visited = set()
        queue = deque([(start_model, 0)])
        lineage = []
        
        while queue:
            current, depth = queue.popleft()
            
            if current in visited or depth > max_depth:
                continue
                
            visited.add(current)
            
            if current != start_model:
                lineage.append({
                    'model': current,
                    'depth': depth,
                    'columns': node_info.get(current, {}).get('columns', [])
                })
            
            for neighbor in deps_dict.get(current, []):
                if neighbor not in visited:
                    queue.append((neighbor, depth + 1))
        
        return lineage
    
    result = {
        'model_info': node_info.get(model_name, {}),
        'lineage': {}
    }
    
    if direction in ['upstream', 'both']:
        result['lineage']['upstream'] = trace_lineage(model_name, upstream_deps, max_depth)
    
    if direction in ['downstream', 'both']:
        result['lineage']['downstream'] = trace_lineage(model_name, downstream_deps, max_depth)
    
    print(json.dumps(result, indent=2))
    
except Exception as e:
    print(json.dumps({'error': str(e)}), file=sys.stderr)
    sys.exit(1)

PYTHON_SCRIPT
"$MANIFEST_PATH" "$MODEL_NAME" "$DIRECTION" "$MAX_DEPTH")

if [ $? -ne 0 ]; then
    print_error "Failed to analyze dbt dependencies"
    exit 1
fi

UPSTREAM_COUNT=$(echo "$LINEAGE_ANALYSIS" | jq '.lineage.upstream // [] | length')
DOWNSTREAM_COUNT=$(echo "$LINEAGE_ANALYSIS" | jq '.lineage.downstream // [] | length')

print_success "Found $UPSTREAM_COUNT upstream models and $DOWNSTREAM_COUNT downstream models"

# Step 6: Generate report
print_status "Step 6: Generating lineage report..."

REPORT_FILE="$RESULTS_DIR/${MODEL_NAME}__${COLUMN_NAME}__lineage.md"
TIMESTAMP=$(date '+%Y-%m-%d %H:%M:%S')

cat > "$REPORT_FILE" << EOF
# Column Lineage Report

**Generated**: $TIMESTAMP  
**Model**: \`$MODEL_NAME\`  
**Column**: \`$COLUMN_NAME\`  
**Data Type**: $DATA_TYPE  
**Snowflake Location**: \`$DATABASE.$SCHEMA.$TABLE.$COLUMN_NAME\`

---

## Summary

- **Direction**: $DIRECTION
- **Max Depth**: $MAX_DEPTH
- **Upstream Models**: $UPSTREAM_COUNT
- **Downstream Models**: $DOWNSTREAM_COUNT
- **Queries Analyzed**: $LINEAGE_COUNT (last 90 days)

EOF

# Add upstream lineage
if [ "$DIRECTION" = "upstream" ] || [ "$DIRECTION" = "both" ]; then
    cat >> "$REPORT_FILE" << EOF

## â¬†ï¸ Upstream Lineage (Sources)

These models and columns feed into \`$MODEL_NAME.$COLUMN_NAME\`:

EOF

    if [ "$UPSTREAM_COUNT" -gt 0 ]; then
        echo "$LINEAGE_ANALYSIS" | jq -r '.lineage.upstream[] | 
            "### " + .model + " (depth " + (.depth | tostring) + ")\n" +
            "**Columns**: " + (.columns | join(", ")) + "\n"
        ' >> "$REPORT_FILE"
    else
        echo "âœ… No upstream dependencies found (this may be a base model)." >> "$REPORT_FILE"
    fi
fi

# Add downstream lineage
if [ "$DIRECTION" = "downstream" ] || [ "$DIRECTION" = "both" ]; then
    cat >> "$REPORT_FILE" << EOF

## â¬‡ï¸ Downstream Lineage (Consumers)

These models consume \`$MODEL_NAME.$COLUMN_NAME\`:

EOF

    if [ "$DOWNSTREAM_COUNT" -gt 0 ]; then
        echo "$LINEAGE_ANALYSIS" | jq -r '.lineage.downstream[] | 
            "### " + .model + " (depth " + (.depth | tostring) + ")\n" +
            "**Columns**: " + (.columns | join(", ")) + "\n"
        ' >> "$REPORT_FILE"
    else
        echo "âœ… No downstream dependencies found (this column may be unused)." >> "$REPORT_FILE"
    fi
fi

# Add Snowflake query usage
cat >> "$REPORT_FILE" << EOF

## ðŸ“Š Snowflake Query Usage (Last 90 Days)

EOF

if [ "$LINEAGE_COUNT" -gt 0 ]; then
    cat >> "$REPORT_FILE" << EOF
Found $LINEAGE_COUNT queries that accessed or modified this table.

**Sample Queries:**

EOF
    
    echo "$SNOWFLAKE_LINEAGE" | jq -r 'limit(5; .[]) | 
        "- **" + .QUERY_ID + "** (" + .QUERY_START_TIME + ") by " + .USER_NAME
    ' >> "$REPORT_FILE"
    
    cat >> "$REPORT_FILE" << EOF

**Note**: Column-level lineage from ACCESS_HISTORY requires parsing query JSON arrays.
This report shows table-level query patterns. For detailed column lineage, examine
the \`DIRECT_OBJECTS_ACCESSED\` and \`BASE_OBJECTS_ACCESSED\` fields.

EOF
else
    echo "No query history found for this table in the last 90 days." >> "$REPORT_FILE"
fi

# Add recommendations
cat >> "$REPORT_FILE" << EOF

---

## ðŸ’¡ Recommendations

EOF

if [ "$UPSTREAM_COUNT" -eq 0 ]; then
    cat >> "$REPORT_FILE" << EOF
- âš ï¸ **No upstream dependencies**: This appears to be a base/source model. Verify the column originates from raw data.
EOF
fi

if [ "$DOWNSTREAM_COUNT" -eq 0 ]; then
    cat >> "$REPORT_FILE" << EOF
- âš ï¸ **No downstream consumers**: This column may be unused. Consider removing if not needed.
EOF
fi

if [ "$LINEAGE_COUNT" -eq 0 ]; then
    cat >> "$REPORT_FILE" << EOF
- âš ï¸ **No query history**: This table hasn't been queried in 90 days. Verify it's still needed.
EOF
fi

cat >> "$REPORT_FILE" << EOF

## ðŸ” Next Steps

1. **Review upstream sources**: Ensure data quality at the source
2. **Check downstream impact**: Understand how changes affect consumers
3. **Validate transformations**: Review SQL in each model to understand column transformations
4. **Document lineage**: Add column descriptions to dbt YAML files

---

**Command**: \`get-column-lineage $MODEL_NAME $COLUMN_NAME $([ "$DIRECTION" != "both" ] && echo "--$DIRECTION") --depth $MAX_DEPTH\`
EOF

print_success "Report generated: $REPORT_FILE"

# Final summary
echo ""
print_success "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
print_success "Column Lineage Analysis Complete"
print_success "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
echo ""
print_status "ðŸ“Š SUMMARY:"
echo "   â€¢ Model: $MODEL_NAME"
echo "   â€¢ Column: $COLUMN_NAME"
echo "   â€¢ Upstream: $UPSTREAM_COUNT models"
echo "   â€¢ Downstream: $DOWNSTREAM_COUNT models"
echo "   â€¢ Queries: $LINEAGE_COUNT in last 90 days"
echo ""
print_status "ðŸ“ REPORT:"
echo "   â€¢ $REPORT_FILE"
echo ""

exit 0
